{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the following notebook, I will be modeling Airbnb Listings data to create a price predictor to better understand the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set notebook preferences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set options for pandas\n",
    "pd.set_option('display.max_columns',1_000)\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "#Set options for numpy\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#Set visualization preferences\n",
    "plt.style.use('fivethirtyeight')\n",
    "#print(plt.style.available)\n",
    "\n",
    "#Surpress warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to data\n",
    "path = r'C:\\Users\\kishe\\Documents\\Data Science\\Projects\\Python Projects\\In Progress\\Airbnb - San Francisco Listings Analysis\\Data\\03_Processed'\n",
    "\n",
    "#Read in training data and labels\n",
    "df = pd.read_csv(path + '/2020_0608_Listings_Processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display data and shape\n",
    "print('Data shape: {}\\n'.format(df.shape))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split data into training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate labels from data\n",
    "X = df.drop('price', axis = 1)\n",
    "y = df['price']\n",
    "\n",
    "#Check\n",
    "print('X shape:{}\\ny shape:{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import splitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split Data\n",
    "X_train, X_test, y_train, y_test =  train_test_split(\n",
    "                                    X,y, test_size = .25, random_state = 42)\n",
    "\n",
    "#Check\n",
    "print('Training data:{} | Training labels:{}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data:{} | Test labels:{}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop Base Model - Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build base model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in Libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from Regression_Metrics import regression_metrics #Prints regression metrics \n",
    "\n",
    "#Init column transformer for data type\n",
    "numeric_transformer = Pipeline([('scaler', MinMaxScaler())])\n",
    "categorical_transformer = Pipeline([('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#Store column transform for pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, X_train.select_dtypes(include=['int64','float64']).columns),\n",
    "                                              ('cat', categorical_transformer, X_train.select_dtypes(include=['object']).columns)])\n",
    "\n",
    "#Init base model as regressor\n",
    "regressors = DecisionTreeRegressor(random_state=12)\n",
    "\n",
    "#Init pipe\n",
    "pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                ('model', regressors)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make and Evaluate Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement model\n",
    "preds = cross_val_predict(pipe, X_train,y_train, n_jobs=-1)\n",
    "\n",
    "#Evaluate\n",
    "regression_metrics('Base DecisionTreeRegressor', X_train, y_train,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model pipeline development\n",
    "\n",
    "**Objective: Select best base model to optimize and deploy on test data**\n",
    "\n",
    "*Models to try:*\n",
    "- Ensemble methods\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor,ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize pipeline components**\n",
    "\n",
    "Will create a list of regression models w/ a corresponding list of parameters to be fit into a pipeline. Parameters will be brief and we'll later optimize the best performing model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of model names to be used in a print funtion later when aggregating model evaluation metrics\n",
    "model_names = [\n",
    "    'RandomForestRegressor',\n",
    "    'GradientBoostingRegressor',\n",
    "    'AdaBoostRegressor',\n",
    "    'ExtraTreesRegressor',\n",
    "    'XGBRegressor',\n",
    "]\n",
    "\n",
    "#Init models into a list to loop over in pipeline to evaluate all base model performances\n",
    "regressors = [\n",
    "    RandomForestRegressor(random_state = 42, n_jobs=-1),\n",
    "    GradientBoostingRegressor(random_state = 42,),\n",
    "    AdaBoostRegressor(random_state = 42,),\n",
    "    ExtraTreesRegressor(random_state = 42, n_jobs=-1),\n",
    "    XGBRegressor(random_state = 42, n_jobs=-1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build preliminary pipeline, evaluate results, and select model for futher development**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement pipe that tests evaluation metrics for all regressors\n",
    "for name,regressor in zip(model_names, regressors):\n",
    "    pipe.steps.pop(1) #Delete previous model in pipeline\n",
    "    pipe.steps.append(['model',regressor]) #Add new model\n",
    "\n",
    "    predictions = cross_val_predict(pipe, X_train, y_train, n_jobs=-1)\n",
    " \n",
    "    #Evaluate\n",
    "    regression_metrics(name, X_train, y_train,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without much tuning, our best models for this data set were RandomForestRegressor and the ExtraTreesRegressor. We'll go with the RandomForestRegresor to optimize for our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Hyperparameters of RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomSearch CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init libraries\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Set list with evaluation metrics for RandomizedSearchCV\n",
    "scoring = ['r2','neg_mean_absolute_error','neg_mean_squared_error']\n",
    "\n",
    "#Create list of model names for later loop\n",
    "model_names = [\n",
    "    'RandomForestRegressor',\n",
    "    ]\n",
    "\n",
    "#Init models \n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "#Init parameters for RandomSearchCV evaluation to search over\n",
    "parameters = [\n",
    "    {'model__n_estimators':[200,300],\n",
    "    'model__max_depth':[15,20,25],\n",
    "    'model__max_features': ['auto', 'sqrt'],\n",
    "    'model__random_state' : [42], \n",
    "    'model__n_jobs': [-1]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline with parameter grid to search over base models(randomsearch cv)\n",
    "for name, regressor, parameter in zip(model_names, regressors, parameters):\n",
    "    pipe.steps.pop(1) #Delete previous model in pipeline\n",
    "    pipe.steps.append(['model',regressor]) #Add new model\n",
    "    \n",
    "    reg = RandomizedSearchCV(pipe, param_distributions=parameter, n_jobs=-1, scoring=scoring, refit='neg_mean_squared_error')\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"{} Random Search Results:\".format(name))\n",
    "    print('Avg RMSE:',np.mean(np.sqrt(-1 * (reg.cv_results_['mean_test_neg_mean_squared_error']))))\n",
    "    print('Avg MAE:',np.mean(-1 * reg.cv_results_['mean_test_neg_mean_absolute_error']))\n",
    "    r2 = np.mean(reg.cv_results_['mean_test_r2'])\n",
    "    print('Avg R2:',r2)\n",
    "    adj_r2 = 1 - (1-r2)*(len(y_train)-1)/(len(y_train)-X_train.shape[1]-1)\n",
    "    print('Avg Adjusted R2:',adj_r2)\n",
    "    print(\"\\n The best estimator across ALL searched params:\\n\", reg.best_estimator_)\n",
    "    print(\"\\n The best parameters across searched parameters:\\n\", reg.best_params_)\n",
    "    print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch CV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init parameters for RandomSearchCV evaluation to search over\n",
    "parameters = [\n",
    "    {'model__n_estimators':[300, 400, 500],\n",
    "    'model__max_depth':[13,15, 17],\n",
    "    'model__learning_rate': [.1],\n",
    "    'model__random_state' : [42], \n",
    "    'model__n_jobs': [-1]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor Random Search Results:\n",
      "RMSE: 15.125169645337053\n",
      "MAE: 5.492793147794266\n",
      "R2: 0.9721892029756335\n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " Pipeline(memory=None,\n",
      "         steps=[('model',\n",
      "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
      "                              colsample_bylevel=1, colsample_bynode=1,\n",
      "                              colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                              importance_type='gain',\n",
      "                              interaction_constraints='', learning_rate=0.1,\n",
      "                              max_delta_step=0, max_depth=13,\n",
      "                              min_child_weight=1, missing=nan,\n",
      "                              monotone_constraints='()', n_estimators=500,\n",
      "                              n_jobs=-1, num_parallel_tree=1,\n",
      "                              objective='reg:squarederror', random_state=42,\n",
      "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                              subsample=1, tree_method='exact',\n",
      "                              validate_parameters=1, verbosity=None))],\n",
      "         verbose=False)\n",
      "\n",
      " The best parameters across searched parameters:\n",
      " {'model__n_estimators': 500, 'model__max_depth': 13, 'model__learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#Create pipeline with parameter grid to search over XGBRegressor \n",
    "\n",
    "pipe = Pipeline([('model',XGBRegressor(random_state = 42, n_jobs = -1))])\n",
    "rand_xbr = RandomizedSearchCV(pipe, param_distributions=parameters, n_jobs=-1, scoring=scoring, refit='neg_mean_squared_error')\n",
    "rand_xbr.fit(X_train_transformed, y_train)\n",
    "print(\"XGBRegressor Random Search Results:\")\n",
    "print('RMSE:',np.mean(np.sqrt(-1 * (rand_xbr.cv_results_['mean_test_neg_mean_squared_error']))))\n",
    "print('MAE:',np.mean(-1 * rand_xbr.cv_results_['mean_test_neg_mean_absolute_error']))\n",
    "print('R2:',np.mean(rand_xbr.cv_results_['mean_test_r2']))\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", rand_xbr.best_estimator_)\n",
    "print(\"\\n The best parameters across searched parameters:\\n\", rand_xbr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspect Feature Importance of Tuned RandomForest Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('selector',\n",
       "                                        SelectFromModel(estimator=DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                                        criterion='mse',\n",
       "                                                                                        max_depth=10,\n",
       "                                                                                        max_features=None,\n",
       "                                                                                        max_leaf_nodes=None,\n",
       "                                                                                        min_impurity_decrease=0.0,\n",
       "                                                                                        min_impurity_split=None,\n",
       "                                                                                        min_samples_leaf=1,\n",
       "                                                                                        min_samples_split=2,\n",
       "                                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                                        presort='deprecated...\n",
       "                                                     random_state=42,\n",
       "                                                     reg_alpha=None,\n",
       "                                                     reg_lambda=None,\n",
       "                                                     scale_pos_weight=None,\n",
       "                                                     subsample=None,\n",
       "                                                     tree_method=None,\n",
       "                                                     validate_parameters=None,\n",
       "                                                     verbosity=None))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'model__learning_rate': [0.1],\n",
       "                         'model__max_depth': [13],\n",
       "                         'model__n_estimators': [500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Set final params of XGBRegressor\n",
    "final_params=  {'model__n_estimators': [500], \n",
    "                'model__max_depth': [13], \n",
    "                'model__learning_rate': [0.1]}\n",
    "\n",
    "\n",
    "\n",
    "#Build final pipeline\n",
    "final_pipe = Pipeline([('selector', selector),\n",
    "                      ('model', XGBRegressor(random_state = 42, n_jobs = -1))])\n",
    "\n",
    "#Init GridSearchCV and fit to training data\n",
    "grid = GridSearchCV(final_pipe, final_params, cv =5, n_jobs=-1)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write final regressorina pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path for test data and tunes pipeline\n",
    "path_test = r'C:\\Users\\kishe\\Documents\\Data Science\\Projects\\Python\\In Progress\\Airbnb - San Francisco\\Data\\04_Test_Data'\n",
    "path_pipe = r'C:\\Users\\kishe\\Documents\\Data Science\\Projects\\Python\\In Progress\\Airbnb - San Francisco\\Project_Codes\\05_Evaluation'\n",
    "\n",
    "#Write pipeline\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(grid.best_estimator_, path_pipe + '/xgbr_regressor.pkl', compress = 1)\n",
    "\n",
    "#Write test data\n",
    "X_test.to_csv(path_test + '/2020_0614_Listings_Test_Data.csv')\n",
    "y_test.to_csv(path_test + '/2020_0614_Listings_Test_Labels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Airbnb_Listings",
   "language": "python",
   "name": "airbnb_listings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
